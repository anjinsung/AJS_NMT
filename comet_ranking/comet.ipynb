{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6677abf-8e90-48f8-879e-8683fe480754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ee63d0-1a72-481c-97cd-cac5abded02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1ef58f-7999-44b0-8332-6017608894e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model_dir = \"./chkpt/checkpoint-37920\"\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_dir)\n",
    "t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_model_dir)\n",
    "\n",
    "t5_model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b8dc66-e572-49cf-a66a-5a4f01d6806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbart_model_dir = \"./checkpoint-71870\"\n",
    "mbart_tokenizer = AutoTokenizer.from_pretrained(mbart_model_dir)\n",
    "mbart_model = AutoModelForSeq2SeqLM.from_pretrained(mbart_model_dir)\n",
    "\n",
    "mbart_model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11e602f-31a0-446f-9552-4de1c6dfe88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"norm_04_front.txt\", \"r\") as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "input_text = [t.strip() for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d7cebfa-5a13-4f81-8db7-49c488c5cc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjinsung/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_inputs = t5_tokenizer(input_text, return_tensors=\"pt\", padding=True, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd0a04a-50a3-4a12-af54-66734fdaf716",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbart_inputs = mbart_tokenizer(input_text, return_tensors=\"pt\", padding=True, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5926e00-7f60-49fd-ae75-5648d06c7822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([234, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_mt = t5_model.generate(\n",
    "    **t5_inputs,\n",
    "    max_length=64,\n",
    "    num_beams=5,\n",
    ")\n",
    "\n",
    "t5_mt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d4d0bd0-baae-4a46-ab9a-b217ed6ac241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([234, 40])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbart_mt = mbart_model.generate(\n",
    "    **mbart_inputs,\n",
    "    max_length=64,\n",
    "    num_beams=5,\n",
    ")\n",
    "\n",
    "mbart_mt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c477f813-8680-445c-856a-261f50d8d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_preds = t5_tokenizer.batch_decode(t5_mt, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "431892d0-1e4b-40a5-8781-8a526ce225a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbart_preds = mbart_tokenizer.batch_decode(mbart_mt, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cec281d5-8199-49ef-ad66-f2c0c4c81ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33a53743-f9e0-47c8-8856-6e0599f78f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e56bd8094ac4e1e91c4456edd5f2056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5063fe2c-9eb8-4df2-81d1-10e48c27b2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db262e447aa4490a3ddb2cec9ddcc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a93728d9e1471ea880f6ec9f5a462f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0c4a0b4e17/README.md:   0%|          | 0.00/3.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6b69ba13a94d5880a877432cd8ad17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a0b4e17/hparams.yaml:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c198460cfd94c3bacedc6613b1b7281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b4e17/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa0f01e26ce4680b6019a466a1b7201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1d0c4a0b4e17/LICENSE:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2fc0bc1c834e2c90a091eccf7646ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.ckpt:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file .cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/f3999e782013262c31521902cd641d0c4a0b4e17/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1364f78ace194e52bdc61f1a4fcbcc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cf67b0d2a04c619a8bec8edabc46f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941ac79791c54a419164646e2c1289b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/513 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n",
      "/home/anjinsung/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:165: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n",
    "model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "739eabd4-aeeb-4769-9ea4-625bc518ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_data = []\n",
    "\n",
    "for i in range(len(input_text[:-2])):\n",
    "    d = {\"src\" : input_text[i], \"mt\" : t5_preds[i]}\n",
    "    t5_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c381b64-1828-49f0-aa60-1cc7ed7c70cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbart_data = []\n",
    "\n",
    "for i in range(len(input_text[:-2])):\n",
    "    d = {\"src\" : input_text[i], \"mt\" : mbart_preds[i]}\n",
    "    mbart_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e65e6937-b6fa-4ac6-9a34-2a042d27c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████████████| 29/29 [00:00<00:00, 52.77it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████████████| 29/29 [00:00<00:00, 50.44it/s]\n"
     ]
    }
   ],
   "source": [
    "t5_model_output = model.predict(t5_data, batch_size=8, gpus=1)\n",
    "mbart_model_output = model.predict(mbart_data, batch_size=8, gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0639a074-1a66-4b96-b6aa-a0f762bbf1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction([('scores', [0.5267308354377747, 0.8439666032791138, 0.8650377988815308, 0.8415365219116211, 0.8602891564369202, 0.7377151250839233, 0.777255117893219, 0.7878456115722656, 0.831110954284668, 0.7602830529212952, 0.69084632396698, 0.8619044423103333, 0.554877519607544, 0.8020641803741455, 0.5511572957038879, 0.753432035446167, 0.7443373203277588, 0.8270370960235596, 0.8546015024185181, 0.5719770789146423, 0.8011908531188965, 0.7981908917427063, 0.7643568515777588, 0.8621553778648376, 0.7786390781402588, 0.7799329161643982, 0.6840822100639343, 0.8383660316467285, 0.6575391292572021, 0.6830523610115051, 0.7759293913841248, 0.7890756726264954, 0.8355790376663208, 0.7698943614959717, 0.6161118745803833, 0.7917062640190125, 0.7781872749328613, 0.7127256393432617, 0.7808287739753723, 0.7818140983581543, 0.6804454922676086, 0.8106083869934082, 0.8504108190536499, 0.8094045519828796, 0.8075203895568848, 0.8742960691452026, 0.8694612383842468, 0.7026063799858093, 0.7357319593429565, 0.8244891166687012, 0.48331570625305176, 0.8175086379051208, 0.6880263090133667, 0.8233351111412048, 0.8651931285858154, 0.6289042234420776, 0.7818396687507629, 0.8046761155128479, 0.7516710162162781, 0.5313816666603088, 0.7648335099220276, 0.7914378046989441, 0.672867476940155, 0.6545662879943848, 0.7229155898094177, 0.7910748720169067, 0.6733679175376892, 0.797518253326416, 0.6156195402145386, 0.8260629177093506, 0.6214148998260498, 0.829721212387085, 0.6938958764076233, 0.8129223585128784, 0.7349749803543091, 0.6721306443214417, 0.7398532629013062, 0.6487951278686523, 0.7673806548118591, 0.7420793175697327, 0.5881047248840332, 0.7797029614448547, 0.803713321685791, 0.85041344165802, 0.7949180006980896, 0.8494789600372314, 0.8238656520843506, 0.8113062977790833, 0.6526502966880798, 0.7691692113876343, 0.8566489219665527, 0.7354934215545654, 0.8369153738021851, 0.6975563168525696, 0.8442342281341553, 0.7597678303718567, 0.724141538143158, 0.8211939334869385, 0.8384048938751221, 0.5824666023254395, 0.7124931812286377, 0.7616150975227356, 0.8171947002410889, 0.8476521968841553, 0.8216031193733215, 0.7651472687721252, 0.8436006307601929, 0.6651456952095032, 0.8655307292938232, 0.6926426887512207, 0.6622214317321777, 0.6698048710823059, 0.5296235680580139, 0.8674826622009277, 0.811882734298706, 0.7394840717315674, 0.6773633360862732, 0.6489324569702148, 0.8005982041358948, 0.6950174570083618, 0.5949312448501587, 0.8309359550476074, 0.7575398087501526, 0.68915855884552, 0.6131291389465332, 0.790007472038269, 0.8170412182807922, 0.6154899001121521, 0.857505738735199, 0.778255820274353, 0.8454640507698059, 0.6835286021232605, 0.6321703195571899, 0.8046815991401672, 0.6385937333106995, 0.7452999949455261, 0.8376495838165283, 0.8439337015151978, 0.7598876357078552, 0.8081459999084473, 0.586087703704834, 0.8255046606063843, 0.7407919764518738, 0.774989128112793, 0.853146493434906, 0.7776423692703247, 0.6824167966842651, 0.595207929611206, 0.8023510575294495, 0.6753149032592773, 0.8450804352760315, 0.8079951405525208, 0.683101236820221, 0.6385501623153687, 0.8136696815490723, 0.7512831091880798, 0.7032284736633301, 0.812303364276886, 0.7101079225540161, 0.8279582858085632, 0.657461941242218, 0.823113739490509, 0.803138017654419, 0.6999695301055908, 0.7760648727416992, 0.8343648314476013, 0.673276424407959, 0.7831019163131714, 0.800905168056488, 0.58519446849823, 0.7354409098625183, 0.6218208074569702, 0.764384925365448, 0.8598230481147766, 0.8258854150772095, 0.7986446619033813, 0.7766503691673279, 0.7538230419158936, 0.68136066198349, 0.871430516242981, 0.6650558710098267, 0.6682881116867065, 0.8445149660110474, 0.8774871230125427, 0.8675112724304199, 0.7622698545455933, 0.683907687664032, 0.508527934551239, 0.7225728034973145, 0.702275812625885, 0.5941654443740845, 0.6492090225219727, 0.4258231818675995, 0.755553126335144, 0.4327886998653412, 0.5437713861465454, 0.6033920645713806, 0.7321873903274536, 0.5891244411468506, 0.6899142265319824, 0.6556607484817505, 0.6440289616584778, 0.8084303140640259, 0.7788441777229309, 0.5373008251190186, 0.7283850908279419, 0.6342669725418091, 0.8205534219741821, 0.7524735927581787, 0.7803894877433777, 0.6350259780883789, 0.8042111396789551, 0.7548184394836426, 0.7912696003913879, 0.8477140665054321, 0.4857126772403717, 0.5317957997322083, 0.678453266620636, 0.7926062941551208, 0.6267670392990112, 0.5965611934661865, 0.7110615968704224, 0.8195757865905762, 0.6656012535095215, 0.7562088370323181, 0.7417232394218445, 0.6801306009292603, 0.7129768133163452, 0.8350750207901001, 0.7736879587173462, 0.7697192430496216, 0.8023519515991211]), ('system_score', 0.7396571645192032)])\n"
     ]
    }
   ],
   "source": [
    "print (t5_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea04dffc-583c-4cd6-841e-86b3353c48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction([('scores', [0.8522672653198242, 0.8356373906135559, 0.8798425793647766, 0.8630403876304626, 0.8361042141914368, 0.8177061080932617, 0.8307859301567078, 0.8511328101158142, 0.8679249882698059, 0.7924708724021912, 0.8069255948066711, 0.8584706783294678, 0.6740697026252747, 0.8551435470581055, 0.8667808771133423, 0.764407217502594, 0.8304123878479004, 0.6854071617126465, 0.8738887310028076, 0.6368225812911987, 0.8460184335708618, 0.8091686964035034, 0.8647955656051636, 0.8768606185913086, 0.8404727578163147, 0.7914947271347046, 0.794174313545227, 0.7005800008773804, 0.6632832884788513, 0.8569378852844238, 0.5777081847190857, 0.8559300899505615, 0.8545347452163696, 0.7711442708969116, 0.6102057099342346, 0.8559772968292236, 0.8348658680915833, 0.8208692073822021, 0.8002108335494995, 0.7925904989242554, 0.6342815160751343, 0.8648051023483276, 0.8546004295349121, 0.8344191312789917, 0.8398863077163696, 0.6309350728988647, 0.8694612383842468, 0.817625880241394, 0.6569902300834656, 0.8463424444198608, 0.8516267538070679, 0.8417563438415527, 0.7752665281295776, 0.850009024143219, 0.8805970549583435, 0.7425716519355774, 0.6919018030166626, 0.7209501266479492, 0.8841361999511719, 0.6153890490531921, 0.8046696186065674, 0.8218281865119934, 0.8532018661499023, 0.5593348145484924, 0.7581878900527954, 0.8272020220756531, 0.7564823627471924, 0.837897777557373, 0.7195745706558228, 0.8149219155311584, 0.4751324951648712, 0.8527119159698486, 0.7711163759231567, 0.8236238956451416, 0.5728234052658081, 0.7591667175292969, 0.7042508125305176, 0.7147700786590576, 0.7067009210586548, 0.8747559785842896, 0.8488519787788391, 0.8245961666107178, 0.8300118446350098, 0.8617442846298218, 0.8337645530700684, 0.682653546333313, 0.8474613428115845, 0.8621348142623901, 0.6149743795394897, 0.8321797847747803, 0.8627784848213196, 0.8342289924621582, 0.8326088190078735, 0.8564502000808716, 0.8252345323562622, 0.7976794242858887, 0.7979966402053833, 0.8206720948219299, 0.8340537548065186, 0.5775538086891174, 0.8112066388130188, 0.7925979495048523, 0.8179774880409241, 0.8782035708427429, 0.8590649962425232, 0.697179913520813, 0.8678884506225586, 0.6575482487678528, 0.8685941100120544, 0.8209412693977356, 0.7517186403274536, 0.7337332367897034, 0.5858093500137329, 0.8757932782173157, 0.856669008731842, 0.7498505711555481, 0.6280230283737183, 0.8165537118911743, 0.8342822790145874, 0.7300424575805664, 0.775743842124939, 0.876282811164856, 0.8722468614578247, 0.867617666721344, 0.8053504228591919, 0.8607679009437561, 0.8471172451972961, 0.8388597965240479, 0.862910807132721, 0.7220993041992188, 0.8591042757034302, 0.8446292877197266, 0.659635066986084, 0.8267362117767334, 0.7172826528549194, 0.7525646090507507, 0.8579150438308716, 0.8642159700393677, 0.7912929654121399, 0.8150994777679443, 0.7036958932876587, 0.8465775847434998, 0.7823969125747681, 0.7780243754386902, 0.8545718789100647, 0.8604872226715088, 0.8240829706192017, 0.7653653025627136, 0.7842176556587219, 0.7245677709579468, 0.8183978796005249, 0.6232457756996155, 0.6791350841522217, 0.6338187456130981, 0.8522710800170898, 0.7915430068969727, 0.8516831398010254, 0.8252270221710205, 0.5709642171859741, 0.8624216318130493, 0.8443737626075745, 0.8529919385910034, 0.8227458000183105, 0.7840311527252197, 0.8339411616325378, 0.8597946763038635, 0.6781757473945618, 0.8523201942443848, 0.8797067403793335, 0.5507595539093018, 0.8130382895469666, 0.8640832901000977, 0.7441952228546143, 0.7361874580383301, 0.7078249454498291, 0.8505264520645142, 0.842452347278595, 0.8509913086891174, 0.7651557922363281, 0.8837165832519531, 0.8447193503379822, 0.8805066347122192, 0.833539605140686, 0.8754727840423584, 0.6503427624702454, 0.8226468563079834, 0.751409113407135, 0.7304120659828186, 0.7059323787689209, 0.8673223853111267, 0.6366296410560608, 0.6683028936386108, 0.7305034399032593, 0.8754701614379883, 0.6371055841445923, 0.537354588508606, 0.7514464259147644, 0.7298587560653687, 0.6122776865959167, 0.6261844635009766, 0.8008184432983398, 0.6930657625198364, 0.7863422632217407, 0.7333821654319763, 0.6848846673965454, 0.7472581267356873, 0.711222767829895, 0.7796029448509216, 0.7710209488868713, 0.736436665058136, 0.8131513595581055, 0.8303223252296448, 0.8645436763763428, 0.7997574806213379, 0.8351316452026367, 0.5771545171737671, 0.6317728757858276, 0.8579590320587158, 0.8134796023368835, 0.8051762580871582, 0.5920959711074829, 0.8029406666755676, 0.8357487916946411, 0.528778612613678, 0.7359400987625122, 0.8566252589225769, 0.7254303693771362, 0.7461192011833191, 0.8498325347900391, 0.8012896776199341, 0.7721554636955261, 0.845934271812439]), ('system_score', 0.7819839180286589)])\n"
     ]
    }
   ],
   "source": [
    "print (mbart_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53510ce9-03b7-49ad-b2df-9f43b6870640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: mbart select\n",
      "1: t5 select\n",
      "2: mbart select\n",
      "3: mbart select\n",
      "4: t5 select\n",
      "5: mbart select\n",
      "6: mbart select\n",
      "7: mbart select\n",
      "8: mbart select\n",
      "9: mbart select\n",
      "10: mbart select\n",
      "11: t5 select\n",
      "12: mbart select\n",
      "13: mbart select\n",
      "14: mbart select\n",
      "15: mbart select\n",
      "16: mbart select\n",
      "17: t5 select\n",
      "18: mbart select\n",
      "19: mbart select\n",
      "20: mbart select\n",
      "21: mbart select\n",
      "22: mbart select\n",
      "23: mbart select\n",
      "24: mbart select\n",
      "25: mbart select\n",
      "26: mbart select\n",
      "27: t5 select\n",
      "28: mbart select\n",
      "29: mbart select\n",
      "30: t5 select\n",
      "31: mbart select\n",
      "32: mbart select\n",
      "33: mbart select\n",
      "34: t5 select\n",
      "35: mbart select\n",
      "36: mbart select\n",
      "37: mbart select\n",
      "38: mbart select\n",
      "39: mbart select\n",
      "40: t5 select\n",
      "41: mbart select\n",
      "42: mbart select\n",
      "43: mbart select\n",
      "44: mbart select\n",
      "45: t5 select\n",
      "46: mbart select\n",
      "47: mbart select\n",
      "48: t5 select\n",
      "49: mbart select\n",
      "50: mbart select\n",
      "51: mbart select\n",
      "52: mbart select\n",
      "53: mbart select\n",
      "54: mbart select\n",
      "55: mbart select\n",
      "56: t5 select\n",
      "57: t5 select\n",
      "58: mbart select\n",
      "59: mbart select\n",
      "60: mbart select\n",
      "61: mbart select\n",
      "62: mbart select\n",
      "63: t5 select\n",
      "64: mbart select\n",
      "65: mbart select\n",
      "66: mbart select\n",
      "67: mbart select\n",
      "68: mbart select\n",
      "69: t5 select\n",
      "70: t5 select\n",
      "71: mbart select\n",
      "72: mbart select\n",
      "73: mbart select\n",
      "74: t5 select\n",
      "75: mbart select\n",
      "76: t5 select\n",
      "77: mbart select\n",
      "78: t5 select\n",
      "79: mbart select\n",
      "80: mbart select\n",
      "81: mbart select\n",
      "82: mbart select\n",
      "83: mbart select\n",
      "84: mbart select\n",
      "85: t5 select\n",
      "86: mbart select\n",
      "87: mbart select\n",
      "88: t5 select\n",
      "89: mbart select\n",
      "90: mbart select\n",
      "91: mbart select\n",
      "92: t5 select\n",
      "93: mbart select\n",
      "94: t5 select\n",
      "95: mbart select\n",
      "96: mbart select\n",
      "97: t5 select\n",
      "98: t5 select\n",
      "99: t5 select\n",
      "100: mbart select\n",
      "101: mbart select\n",
      "102: mbart select\n",
      "103: mbart select\n",
      "104: mbart select\n",
      "105: t5 select\n",
      "106: mbart select\n",
      "107: t5 select\n",
      "108: mbart select\n",
      "109: mbart select\n",
      "110: mbart select\n",
      "111: mbart select\n",
      "112: mbart select\n",
      "113: mbart select\n",
      "114: mbart select\n",
      "115: mbart select\n",
      "116: t5 select\n",
      "117: mbart select\n",
      "118: mbart select\n",
      "119: mbart select\n",
      "120: mbart select\n",
      "121: mbart select\n",
      "122: mbart select\n",
      "123: mbart select\n",
      "124: mbart select\n",
      "125: mbart select\n",
      "126: mbart select\n",
      "127: mbart select\n",
      "128: mbart select\n",
      "129: t5 select\n",
      "130: mbart select\n",
      "131: mbart select\n",
      "132: mbart select\n",
      "133: mbart select\n",
      "134: mbart select\n",
      "135: mbart select\n",
      "136: mbart select\n",
      "137: mbart select\n",
      "138: mbart select\n",
      "139: mbart select\n",
      "140: mbart select\n",
      "141: mbart select\n",
      "142: mbart select\n",
      "143: mbart select\n",
      "144: mbart select\n",
      "145: mbart select\n",
      "146: mbart select\n",
      "147: mbart select\n",
      "148: t5 select\n",
      "149: mbart select\n",
      "150: t5 select\n",
      "151: t5 select\n",
      "152: t5 select\n",
      "153: t5 select\n",
      "154: mbart select\n",
      "155: mbart select\n",
      "156: mbart select\n",
      "157: mbart select\n",
      "158: t5 select\n",
      "159: mbart select\n",
      "160: mbart select\n",
      "161: mbart select\n",
      "162: mbart select\n",
      "163: mbart select\n",
      "164: mbart select\n",
      "165: mbart select\n",
      "166: mbart select\n",
      "167: mbart select\n",
      "168: mbart select\n",
      "169: t5 select\n",
      "170: mbart select\n",
      "171: mbart select\n",
      "172: t5 select\n",
      "173: t5 select\n",
      "174: t5 select\n",
      "175: mbart select\n",
      "176: mbart select\n",
      "177: mbart select\n",
      "178: mbart select\n",
      "179: mbart select\n",
      "180: mbart select\n",
      "181: mbart select\n",
      "182: t5 select\n",
      "183: t5 select\n",
      "184: t5 select\n",
      "185: mbart select\n",
      "186: mbart select\n",
      "187: mbart select\n",
      "188: t5 select\n",
      "189: mbart select\n",
      "190: mbart select\n",
      "191: mbart select\n",
      "192: mbart select\n",
      "193: mbart select\n",
      "194: mbart select\n",
      "195: t5 select\n",
      "196: mbart select\n",
      "197: t5 select\n",
      "198: mbart select\n",
      "199: t5 select\n",
      "200: mbart select\n",
      "201: mbart select\n",
      "202: t5 select\n",
      "203: t5 select\n",
      "204: mbart select\n",
      "205: mbart select\n",
      "206: mbart select\n",
      "207: t5 select\n",
      "208: mbart select\n",
      "209: t5 select\n",
      "210: mbart select\n",
      "211: mbart select\n",
      "212: mbart select\n",
      "213: mbart select\n",
      "214: t5 select\n",
      "215: mbart select\n",
      "216: mbart select\n",
      "217: mbart select\n",
      "218: mbart select\n",
      "219: mbart select\n",
      "220: t5 select\n",
      "221: mbart select\n",
      "222: mbart select\n",
      "223: t5 select\n",
      "224: t5 select\n",
      "225: mbart select\n",
      "226: mbart select\n",
      "227: mbart select\n",
      "228: mbart select\n",
      "229: mbart select\n",
      "230: mbart select\n",
      "231: mbart select\n"
     ]
    }
   ],
   "source": [
    "output_text = []\n",
    "\n",
    "for i in range(len(t5_model_output[0])):\n",
    "\n",
    "    if t5_model_output[0][i] > mbart_model_output[0][i]:\n",
    "        print(str(i) + \": t5 select\")\n",
    "        output_text.append(t5_preds[i])\n",
    "    else:\n",
    "        print(str(i) + \": mbart select\")\n",
    "        output_text.append(mbart_preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d082dac1-a2e8-4caf-bf39-48c450810c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, I am Park Tae-joon.',\n",
       " 'In this time we will mathematically understand the linear regression algorithm ',\n",
       " 'As we saw earlier, the linear regression model is a line.',\n",
       " 'And this line can be expressed as a linear equation.',\n",
       " 'For example y can be expressed as ax plus b ',\n",
       " 'Here, A becomes the slope and B becomes the y-intercept.',\n",
       " \"Now, let's take the rotation in this way from now on.\",\n",
       " 'The y section is expressed as theta zero. The slope is expressed as theta one.',\n",
       " 'These two parameters determine the linear equation.',\n",
       " 'The straight line hx will be expressed by adding theta zero and theta one x.',\n",
       " 'So theta zero is the slope of the y section theta one.',\n",
       " 'Hx is a prediction value ',\n",
       " 'But to emphasize that this linear parameter is theta one, it is theta one.',\n",
       " 'Theta was written below h as a subscript.',\n",
       " 'The parameter of this straight line is called theta.',\n",
       " 'It will be a measure of whether it is bad or not.',\n",
       " 'As shown on the screen, as shown in the figure, we are the closest straight line to a given dataset.',\n",
       " 'The straight line is displayed in red ',\n",
       " \"Let's take a look at how to create a linear regression model and use it for prediction.\",\n",
       " 'It seems like you are seeing it.',\n",
       " 'There is an algorithm for linear regression in the middle of the screen.',\n",
       " 'This linear regression algorithm receives the dataset created in the remembering step as an input.',\n",
       " 'It is an algorithm that creates the linear regression model h theta x.',\n",
       " 'How this algorithm works is as discussed in previous lectures.',\n",
       " 'The slope and the y-intercept value are arbitrarily initialized.',\n",
       " \"For example, let's take a look.\",\n",
       " \"Wasn't it all about the algorithm to repeat countless times the process of moving?\",\n",
       " 'So we continue to repeat this simple algorithm ',\n",
       " 'h theta x made in this way is h theta x.',\n",
       " 'The number of rooms or the size of the house.',\n",
       " 'The characteristics were received by input ',\n",
       " 'It tracks predicted values such as housing prices.',\n",
       " 'What is the output?',\n",
       " 'The predicted value is the predicted value of the housing price.',\n",
       " 'The linear regression algorithm is through the linear regression algorithm ',\n",
       " 'I make a model or linear equation h theta x.',\n",
       " 'It is the stage of making predictions.',\n",
       " 'In this picture, the process of creating a dataset at the top is shown.',\n",
       " 'Making hx in a linear regression algorithm is a formulate step.',\n",
       " 'You can confirm that you are alive.',\n",
       " 'In this linear regression algorithm this linear regression algorithm ',\n",
       " 'A model that minimizes the difference between the correct answer value or the label and the predicted value.',\n",
       " 'The method is presented on the screen.',\n",
       " 'A dataset is given on the left side of the screen.',\n",
       " 'The input characteristic is the size of the house.',\n",
       " 'There are several data sets ',\n",
       " 'The second data is x2 y2',\n",
       " 'x3 y4 x4 y4 is like this?',\n",
       " 'The dataset is that this value is already presented in the table ',\n",
       " 'Then, this dataset can be visualized on a two-dimensional plane like the right.',\n",
       " 'How does the visualization work? The horizontal axis is the size of the house.',\n",
       " 'The vertical axis is the price of housing.',\n",
       " 'In addition, you can take points one by one while having all the data.',\n",
       " 'The advantages are displayed on a orange x display.',\n",
       " 'So what are we going to do?',\n",
       " 'If it is specific data, for example, i-th data, then it is specific data.',\n",
       " 'The answer corresponding to the label or yi corresponding to the label ',\n",
       " 'Then the difference in prediction values decreases ',\n",
       " 'Then how do you obtain the predicted value?',\n",
       " 'x of model h theta x is also x.',\n",
       " 'It is only necessary to substitute the i-th data xi.',\n",
       " 'Then, how does the predicted value come out?',\n",
       " \"Let's take an example.\",\n",
       " 'The fourth map and x4 on this screen ',\n",
       " 'We will see y4.',\n",
       " 'How does the correct answer be determined?',\n",
       " 'y4 is shown on the screen.',\n",
       " 'How about the predicted value?',\n",
       " 'Then, the difference between y4 and hx4 is the difference.',\n",
       " 'How did you change the value of theta zero and theta one ',\n",
       " 'This data point corresponding to x4 is the corresponds to x4 ',\n",
       " 'Is it above or below the straight line?',\n",
       " 'Then, depending on whether it is the right or left of the y-axis.',\n",
       " 'It repeats the process of rotating and moving.',\n",
       " 'In this case it is above the line ',\n",
       " 'Then he is on the right side of the y-axis, so how is it?',\n",
       " 'The angle increased ',\n",
       " 'It rotates counterclockwise and increases it.',\n",
       " 'I moved it to the top ',\n",
       " 'Then, what happens in the process?',\n",
       " 'The value of theta one corresponding to the slope also changes.',\n",
       " 'The theta zero value corresponding to the y fragment is also changed.',\n",
       " 'It is only mathematically expressed.',\n",
       " 'I hope you will learn how the linear regression algorithm you learned in the lecture is expressed mathematically.',\n",
       " 'We have expressed the linear regression algorithm we learned a little mathematically.',\n",
       " 'Next we want to supplement the algorithm ',\n",
       " 'We have the means we need.',\n",
       " 'There is a need for a means of measuring how good the corresponding model or straight line is.',\n",
       " 'This method is called a cost function and a cost function ',\n",
       " \"So let's learn about this.\",\n",
       " 'It can be said that this method uses the cost function.',\n",
       " 'Conversely, the cost function is how the model works.',\n",
       " 'There are two models or straight lines on the left and right ',\n",
       " 'The dataset is the same. The four data points are the same. On left and right.',\n",
       " 'The straight lines are different from each other ',\n",
       " 'But looking at it, the left is a bad model, and the right is a good model.',\n",
       " 'Why is the left a bad model and the right a good model?',\n",
       " 'The left is not the closest line to the given data point ',\n",
       " 'The right is a better model or straight line compared to the left ',\n",
       " 'In this case this cost function is this cost function ',\n",
       " 'A large value is assigned to the bad model on the left.',\n",
       " 'A small value is assigned to a good model on the right.',\n",
       " 'So, one straight line came out.',\n",
       " \"Let's see how a cost function suitable for a linear regression model can be defined.\",\n",
       " 'There are two methods: absolute error and square error.',\n",
       " 'There are many lengths that can define a cost function or a cost function ',\n",
       " 'These are the two things we will look at.',\n",
       " 'The absolute error is the absolute error in English ',\n",
       " 'It will be the sum of the vertical distance from one point of the dataset to the straight line.',\n",
       " 'The square error will be the sum of the sum of these vertical distances multiplied.',\n",
       " 'There are two factors. You can define the cost function or cost function with two factors.',\n",
       " 'Then, first, we will define the cost function as absolute error absolute error.',\n",
       " 'absolute error absolute error is each point of the dataset and each point of the dataset.',\n",
       " 'It is the sum of vertical distances between straight lines.',\n",
       " 'Although we looked at the mathematical model, what is needed to calculate this vertical distance?',\n",
       " 'The difference between the label or correct answer value and the predicted value is used.',\n",
       " 'That s right for example the fourth data ',\n",
       " 'What do you do if you go up and down vertically?',\n",
       " \"That's the predicted value when passing through the straight line.\",\n",
       " 'Then, if you go up a little more, you will see it.',\n",
       " \"It's a vertical distance.\",\n",
       " 'So, what will this difference be?',\n",
       " 'It can be a positive or negative value depending on whether the point is above or below the line.',\n",
       " 'So, in order to always change this difference to a positive number, an absolute value is taken.',\n",
       " 'It means that if you have a difference and add all data, it becomes a cost function.',\n",
       " 'Then, a good linear regression model is a model with a line close to the point.',\n",
       " 'Perhaps the latter.',\n",
       " 'How can I make that? It should be made with a line that minimizes the sum of the errors.',\n",
       " 'You will have to choose a line that minimizes the sum of the vertical distance from each point to the line.',\n",
       " 'It s a line where the sum of the highest vertical distance is minimum ',\n",
       " 'In that sense, it means that cost function can be defined.',\n",
       " 'There are two models we saw earlier, the bad model on the left and the good model on the right.',\n",
       " 'We will add errors.',\n",
       " 'There is a vertical distance from each four points to the line, and if you add it up, there is a very long error.',\n",
       " \"Isn't the right right? Isn't the vertical distance from each point to the straight line small? If you add this, there will be a very small error.\",\n",
       " 'The left is large and the right is small.',\n",
       " 'It can be seen that the right is a relatively more suitable model than the left.',\n",
       " 'So how do we use it?',\n",
       " 'If you are given data and there is only one straight line, how do you do it?',\n",
       " 'So, we have to see if we respond.',\n",
       " 'Such a method and how it descends from the calculation phase.',\n",
       " 'somewhere in the mountains.',\n",
       " 'Where is the height?',\n",
       " 'The position of somewhere in the mountain is changed to a straight line, and then the elevation at that location is changed to a cost value.',\n",
       " 'If you see this, the cost function seems like a valley rather than a mountain.',\n",
       " 'An algorithm that descends slowly from the mountain or an algorithm that descends the lowest point in the valley.',\n",
       " 'It is said that it corresponds to a straight line or model.',\n",
       " 'In other words, it corresponds to the height in that point.',\n",
       " 'It s possible to find the best model ',\n",
       " 'If you think about the algorithm that descends from the mountains, think about it.',\n",
       " 'It means that the model changes from one model to a slightly better model through each step ',\n",
       " 'It s a step farther than the current model ',\n",
       " 'It will be more inclined to go down than currently ',\n",
       " 'So through each step each step ',\n",
       " 'It will be replaced with a slightly better model.',\n",
       " 'If you continue to go through this, you will go to the best model.',\n",
       " 'Finally, the best model',\n",
       " 'It will be possible to find the minimum model.',\n",
       " 'Oh so I m looking forward to the method used when going down from the mountain slowly ',\n",
       " 'The method of operation will be described in detail.',\n",
       " 'First, the slope and the initial value of the wire fragment are arbitrarily selected.',\n",
       " 'It is random selection.',\n",
       " 'Then, the value of the cost function is reduced in the direction of decreasing.',\n",
       " 'The slope and the value of the wire fragment continue to change.',\n",
       " 'Continued change will be the key.',\n",
       " 'How to design the process will be the key. How do we do it?',\n",
       " 'We are also trying to help understand.',\n",
       " 'Since visualization is a little difficult to imagine, the problem is simplified.',\n",
       " 'There are no other reasons.',\n",
       " 'On the other hand we reviewed it ',\n",
       " 'As shown here, it has a quadratic function form.',\n",
       " 'And the formula used to change the value is:',\n",
       " 'But what value is deleted ',\n",
       " 'The second step is continuing to repeat this process ',\n",
       " 'This part can be explained by referring to a complex mathematical and polymeric coefficient ',\n",
       " 'Then, let us take an actual example.',\n",
       " \"Let's take a look.\",\n",
       " \"Let's take a look at the first step.\",\n",
       " 'The initial value of the beta is randomly selected at about 5 times.',\n",
       " 'Of course, every time the algorithm is executed, this initial value is changed.',\n",
       " 'So, it may be minus 3 at some point, plus 1 at some point, and then it is different.',\n",
       " 'However, it is said that the initial value changes every time the algorithm is executed. Is the final result also changed?',\n",
       " 'It s not that but I said that the final result is always the same ',\n",
       " 'You will know why it s the same when you execute the algorithm ',\n",
       " 'Then what should I do after selecting the initial value ',\n",
       " 'It is a process of repetition, how did you say that it was repeated?',\n",
       " 'If it is the right of the target point, the slope value is',\n",
       " 'The sign becomes positive.',\n",
       " 'It will be updated in the direction of shrinking because it removes the value ',\n",
       " 'For example, since the initial value is selected randomly, there may be a secondary value on the left of the target point.',\n",
       " 'For example, the initial value was not wrong, but negative.',\n",
       " 'If you execute the algorithm, it may be the initial value of the beta because it is negative.',\n",
       " 'Then how is it? In conclusion, the third is updated in the direction of growing.',\n",
       " \"Let's take a look at why.\",\n",
       " 'The negative number will come out.',\n",
       " 'In addition to the negative value the negative value ',\n",
       " 'It seems like adding a positive value, so how do you do it?',\n",
       " 'In both cases both of these two ',\n",
       " 'It is in the direction of reducing and lowering in the direction of reducing.',\n",
       " 'You look at the middle of the consciousness ',\n",
       " 'It will be a value to set how much beta will be updated.',\n",
       " \"It won't change very much from right to right.\",\n",
       " 'But it was closer to the goal ',\n",
       " 'You will reach the maximum value ',\n",
       " 'The interval to find the minimum value is the interval at which the minimum value is found.',\n",
       " 'If the learning rate is small, it will become small.',\n",
       " 'So, you have to update the beta several times, but you have to update it.',\n",
       " 'It can be seen that you can definitely reach the maximum value ',\n",
       " 'If the learning rate is small, the computer takes more trouble. However, it is.',\n",
       " 'I hope you understand that it can reach the maximum value clearly ',\n",
       " 'Conversely, if the learning rate is high, how will it be?',\n",
       " 'The distance to find the minimum value increases.',\n",
       " 'What if it grows bigger and bigger?',\n",
       " \"It's on the left of the target value.\",\n",
       " 'If you can find the peak value the number of updates may be smaller ',\n",
       " 'If you go throughzigzag, it is not a thousand times, but a thousand times.',\n",
       " 'It can be done only a few times.',\n",
       " 'The number of updates may be reduced.',\n",
       " 'This special case is good.',\n",
       " 'If luck is good, the number of updates may be reduced. Find the minimum value.',\n",
       " 'What is it that you can t find the peak value and expose it ',\n",
       " \"What if this happens? I won't find the minimum price and I'll go to the wrong place.\",\n",
       " 'It is said that there may be such a case.',\n",
       " 'So when the learning rate increases the learning rate increases ',\n",
       " 'The experiment may not be performed and the minimum value may not be found and emitted ',\n",
       " 'So, it is good to set an appropriate value for the learning rate.',\n",
       " 'A smaller value is better than a large one.',\n",
       " 'If the learning rate is small, it converges unconditionally.',\n",
       " 'It is important how well the learning rate parameters are selected to fit the data.',\n",
       " 'It has been changed in various ways, and now experiments are conducted to match the appropriate learning rate to the data.',\n",
       " 'Finding the rate of learning will be what you have to do.',\n",
       " \"I will conclude this week's lecture.\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "049acb83-c44d-411c-b7b8-d0401cdb74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as f:\n",
    "    for o in output_text:\n",
    "        f.write(o)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969c3a9-fab5-4868-9ede-9b9841976b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
